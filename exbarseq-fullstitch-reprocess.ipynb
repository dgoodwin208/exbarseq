{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.053205Z",
     "start_time": "2020-08-26T00:30:46.215386Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "import pickle\n",
    "import warnings\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.morphology import opening, closing, ball, dilation\n",
    "\n",
    "from autograd import grad\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage import color\n",
    "from skimage.feature import register_translation\n",
    "from skimage.morphology import opening, ball\n",
    "from skimage.feature.register_translation import _upsampled_dft\n",
    "from scipy.ndimage import fourier_shift, zoom, gaussian_filter\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from sklearn.decomposition import NMF, non_negative_factorization\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.067125Z",
     "start_time": "2020-08-26T00:30:49.056114Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def high_pass(Y, pct = 10):\n",
    "    Y_new = Y.copy()\n",
    "    for idx in tqdm(range(Y.shape[3])):\n",
    "        Ytemp = Y[:,:,:,idx]\n",
    "        thresh = np.percentile(Ytemp[Ytemp > 0], pct)\n",
    "        Ytemp[Ytemp < thresh] = thresh\n",
    "        Y_new[:,:,:,idx] = Ytemp - thresh\n",
    "\n",
    "    return Y_new\n",
    "\n",
    "def percentile_normalize(Y, pct_low = 95, pct_high = 99):\n",
    "    sf = []\n",
    "    Y_new = Y.copy()\n",
    "    Y_new = Y_new.astype('d')\n",
    "    for idx in tqdm(range(Y.shape[3])):\n",
    "        in_range = np.logical_and(Y[:,:,:,idx] > np.percentile(Y[:,:,:,idx], pct_low), Y[:,:,:,idx] < np.percentile(Y[:,:,:,idx], pct_high)) \n",
    "        if np.min(Y[in_range, idx]) <= 0:\n",
    "            print('WARNING: Percentile values may be poorly scaled...')\n",
    "        scale_fac = np.mean(Y[in_range, idx])\n",
    "        sf.append(scale_fac)\n",
    "        Y_new[:,:,:,idx] = Y[:,:,:,idx]/scale_fac\n",
    "    \n",
    "    Y_new = Y_new*np.median(sf)\n",
    "        \n",
    "    return Y_new\n",
    "\n",
    "def background_opening(Y, size = 3):\n",
    "    strel = ball(size)\n",
    "    Y_new = Y.copy()\n",
    "    for i in tqdm(range(Y.shape[3])):\n",
    "        Y_new[:,:,:,i] = Y[:,:,:,i] - opening(Y[:,:,:,i], strel)\n",
    "    \n",
    "    return Y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.094388Z",
     "start_time": "2020-08-26T00:30:49.070196Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imagesc(img, sz1 = 10, sz2 = 10):\n",
    "    plt.figure(figsize=(sz1,sz2))\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    max_val = np.percentile(img, 99.9) #make sure colors are scaled over whole image\n",
    "    plt.imshow(img, vmin = 0, vmax = max_val)\n",
    "    \n",
    "def viewmask(img, sz1 = 10, sz2 = 15):\n",
    "    plt.figure(figsize=(sz1,sz2))\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    plt.imshow(np.sum(img, 2), vmin = 0)\n",
    "\n",
    "def imagesc3D(vol):\n",
    "    def f(idx):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "        max_val = np.percentile(vol, 99) #make sure colors are scaled over whole image\n",
    "        plt.imshow(vol[:,:, idx], vmin = 0,vmax = max_val)\n",
    "        plt.show()\n",
    "\n",
    "    interactive_plot = interactive(f, idx=IntSlider(value=0, description='slice', max=vol.shape[-1]-1, min=0, continuous_update = False))\n",
    "    output = interactive_plot.children[-1]\n",
    "    output.layout.height = '650px'\n",
    "    return interactive_plot\n",
    "\n",
    "def imagesc4D(vol):\n",
    "    def f(cidx, zidx):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "        max_val = np.percentile(vol, 99) #make sure colors are scaled over whole image\n",
    "        plt.imshow(vol[:,:, zidx,cidx], vmin = 0, vmax = max_val)\n",
    "        plt.show()\n",
    "\n",
    "    interactive_plot = interactive(f, cidx=IntSlider(value=0, description='channel', max=vol.shape[-1]-1, min=0, continuous_update = False), zidx=IntSlider(value=0, description='slice', max=vol.shape[-2]-1, min=0, continuous_update = False))\n",
    "    output = interactive_plot.children[-1]\n",
    "    output.layout.height = '650px'\n",
    "    return interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.102704Z",
     "start_time": "2020-08-26T00:30:49.096996Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def view_components(vol):\n",
    "    def f(idx):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "        plt.imshow(np.sum(vol[:,:, :, idx], 2))\n",
    "        plt.show()\n",
    "\n",
    "    interactive_plot = interactive(f, idx=IntSlider(value=0, description='cell', max=vol.shape[-1]-1, min=0, continuous_update = False))\n",
    "    output = interactive_plot.children[-1]\n",
    "    output.layout.height = '650px'\n",
    "    return interactive_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.125877Z",
     "start_time": "2020-08-26T00:30:49.104760Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def greedy_init(Y, n_components, sigma, verbose = True):\n",
    "    devs = 4\n",
    "    #save dimensions of Y\n",
    "    d1, d2, d3, T = Y.shape\n",
    "\n",
    "    #initialize objects\n",
    "    dsigma = 2*np.array(sigma)+1\n",
    "    W = np.zeros((d1, d2, d3, n_components))\n",
    "    H = np.zeros((n_components,T))\n",
    "    centers = np.zeros((n_components, 3))\n",
    "    Y_init = Y.copy()\n",
    "    Y_init = Y_init.astype('double')\n",
    "\n",
    "    #gaussian blur image\n",
    "    rho = np.array([gaussian_filter(Y_init[:,:,:, i], sigma, mode = 'constant', output = 'double', truncate = devs) for i in range(T)])\n",
    "    rho = np.moveaxis(rho, 0, -1)\n",
    "\n",
    "    #find sum image\n",
    "    v = np.sum(rho, 3)\n",
    "\n",
    "    for k in range(n_components):\n",
    "        #find max location and boundaries\n",
    "        ix, iy, iz = np.unravel_index(np.argmax(v), v.shape)\n",
    "        xmax, xmin = min(v.shape[0]-1, ix + dsigma[0]), max(0, ix - dsigma[0])\n",
    "        ymax, ymin = min(v.shape[1]-1, iy + dsigma[1]), max(0, iy - dsigma[1])\n",
    "        zmax, zmin = min(v.shape[2]-1, iz + dsigma[2]), max(0, iz - dsigma[2])\n",
    "\n",
    "        data = Y_init[xmin:xmax, ymin:ymax, zmin:zmax, :]\n",
    "        dims = data.shape\n",
    "        data = np.reshape(data, (dims[0]*dims[1]* dims[2], dims[3]))\n",
    "        rA, C, niter = non_negative_factorization(data, n_components = 1, alpha = 0.2, max_iter = 100, tol = 1e-50)\n",
    "\n",
    "        #save extracted components\n",
    "        A = np.reshape(rA, (dims[0], dims[1],dims[2]))\n",
    "        W[xmin:xmax, ymin:ymax, zmin:zmax,k] = A\n",
    "        H[k, :] = C\n",
    "        centers[k,:] = [ix, iy, iz]\n",
    "        \n",
    "        if k < (n_components-1): #if not last component\n",
    "            #update Y_init\n",
    "            removed_data = np.dot(rA, C)\n",
    "            removed_data = np.reshape(removed_data, (dims[0], dims[1], dims[2], dims[3]))\n",
    "            \n",
    "            temp = Y_init[xmin:xmax, ymin:ymax, zmin:zmax, :] - removed_data\n",
    "            temp[temp < 0] = 0 #remove negative values\n",
    "            Y_init[xmin:xmax, ymin:ymax, zmin:zmax, :] = temp\n",
    "            \n",
    "            rho_xmax, rho_xmin = min(v.shape[0]-1, xmax+devs*sigma[0]), max(0, xmin-devs*sigma[0])\n",
    "            rho_ymax, rho_ymin = min(v.shape[1]-1, ymax+devs*sigma[1]), max(0, ymin-devs*sigma[1])\n",
    "            rho_zmax, rho_zmin = min(v.shape[2]-1, zmax+devs*sigma[2]), max(0, zmin-devs*sigma[2])\n",
    "            \n",
    "            inp_xmax, inp_xmin = min(v.shape[0]-1, xmax+2*devs*sigma[0]), max(0, xmin-2*devs*sigma[0])\n",
    "            inp_ymax, inp_ymin = min(v.shape[1]-1, ymax+2*devs*sigma[1]), max(0, ymin-2*devs*sigma[1])\n",
    "            inp_zmax, inp_zmin = min(v.shape[2]-1, zmax+2*devs*sigma[2]), max(0, zmin-2*devs*sigma[2])\n",
    "            #update rho\n",
    "            for i in range(T):\n",
    "                rho[:,:,:,i] = gaussian_filter(Y_init[:,:,:, i], sigma, mode = 'constant', output = 'double', truncate = devs)\n",
    "\n",
    "            #update sum image\n",
    "            v = np.sum(rho, 3)\n",
    "        if verbose:\n",
    "            print('Found Component #' + str(k+1) + '...')\n",
    "    return W, H, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.136648Z",
     "start_time": "2020-08-26T00:30:49.128000Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def create_3D_patches(dims, patchsize, overlap):\n",
    "    xdim, ydim, zdim = dims\n",
    "    px, py, pz = patchsize\n",
    "    ovlp_x, ovlp_y, ovlp_z = overlap\n",
    "    \n",
    "    itx, ity, itz = px - ovlp_x, py - ovlp_y, pz - ovlp_z\n",
    "    \n",
    "    xvals = [0]\n",
    "    yvals = [0]\n",
    "    zvals = [0]\n",
    "    \n",
    "    while xvals[-1]+px < xdim:\n",
    "        xvals.append(xvals[-1] + itx)\n",
    "        \n",
    "    while yvals[-1]+py< ydim:\n",
    "        yvals.append(yvals[-1] + ity)\n",
    "        \n",
    "    while zvals[-1]+pz < zdim:\n",
    "        zvals.append(zvals[-1] + itz)\n",
    "        \n",
    "    n_patches = len(xvals) * len(yvals) * len(zvals)\n",
    "    patches = np.zeros((2,3, n_patches))\n",
    "    \n",
    "    i = 0\n",
    "    for xmin in xvals:\n",
    "        for ymin in yvals:\n",
    "            for zmin in zvals:\n",
    "                xmax, ymax, zmax = min(xmin+px, xdim),min(ymin+py, ydim),min(zmin+pz, zdim)\n",
    "                patches[:,:, i] = np.array([[xmin, ymin, zmin], [xmax, ymax, zmax]])\n",
    "                i += 1\n",
    "    \n",
    "    return patches.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.144954Z",
     "start_time": "2020-08-26T00:30:49.138533Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def process_patch(Y, n_components, sigma, patch_list):\n",
    "    W_init, H_init, centers = greedy_init(Y, n_components, sigmas)\n",
    "    \n",
    "    W_init, H_init, pl = merge_components(W_init, H_init, patch_list)\n",
    "    n_components = W_init.shape[-1]\n",
    "    \n",
    "    d1,d2,d3,T = Y.shape\n",
    "    dim = d1*d2*d3\n",
    "\n",
    "    Y = np.reshape(Y, (dim, T))\n",
    "    W_init = np.reshape(W_init, (dim, n_components))\n",
    "    \n",
    "    A, C, niter = non_negative_factorization(Y, W = W_init, H = H_init, n_components = n_components, \n",
    "                update_H = False, verbose = False, alpha = 0.5, max_iter = 200, tol = 1e-4, init = 'custom', l1_ratio = 1)\n",
    "    A = np.reshape(A, (d1,d2,d3,n_components))\n",
    "        \n",
    "    return A,C, pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.151948Z",
     "start_time": "2020-08-26T00:30:49.146826Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def embed_patch_results(A, full_dims, patch_min_coords, patch_max_coords):\n",
    "    T = A.shape[-1]\n",
    "    xmin, ymin, zmin = patch_min_coords\n",
    "    xmax, ymax, zmax = patch_max_coords\n",
    "    \n",
    "    full = np.zeros([full_dims[0], full_dims[1], full_dims[2], T])\n",
    "    full[xmin:xmax, ymin:ymax, zmin:zmax, :] = A\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.160138Z",
     "start_time": "2020-08-26T00:30:49.155704Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def remove_empty_components(A, C, patch_list):\n",
    "    Aempty = np.sum(A, (0,1,2)) == 0\n",
    "    Cempty = np.sum(C, 1) == 0\n",
    "    remove = np.where(np.logical_or(Aempty, Cempty))[0]\n",
    "    \n",
    "    A = np.delete(A, remove, -1)\n",
    "    C = np.delete(C, remove, 0)\n",
    "    patch_list = np.delete(patch_list, remove, 0)\n",
    "        \n",
    "    return A, C, patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.168073Z",
     "start_time": "2020-08-26T00:30:49.162472Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def connected_components(adjacency, min_size = 0):\n",
    "    viewed = set()\n",
    "    components = []\n",
    "    for seed in range(adjacency.shape[0]):\n",
    "        if seed not in viewed:\n",
    "            component = [seed]\n",
    "            for node in component:\n",
    "                viewed.add(node)\n",
    "                connected = np.where(adjacency[seed, :] > 0)[0]\n",
    "                \n",
    "                for n in connected: \n",
    "                    if n not in viewed:\n",
    "                        component.append(n)\n",
    "                        viewed.add(n)\n",
    "            \n",
    "            components.append(component)\n",
    "    \n",
    "    components = [component for component in components if len(component) >= min_size]\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.173560Z",
     "start_time": "2020-08-26T00:30:49.169918Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def patch_mismatch(patch_list):\n",
    "    mat = np.zeros((patch_list.shape[0], patch_list.shape[0]))\n",
    "    for i in range(patch_list.shape[0]):\n",
    "        mat[i, :] = patch_list != patch_list[i]\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.182514Z",
     "start_time": "2020-08-26T00:30:49.175624Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def merge_components(A, C, patch_list, spatial_thresh = 0.05, crosspatch_spatial_thresh = 0.05, temporal_thresh = 0.85):\n",
    "    spatial_correlation = create_spatial_correlation(A)\n",
    "    temporal_correlation = create_temporal_correlation(C)\n",
    "    patch_mis = patch_mismatch(patch_list)\n",
    "    \n",
    "    spatial_overlap = (spatial_correlation > spatial_thresh)\n",
    "    temporal_overlap = (temporal_correlation > temporal_thresh)\n",
    "    \n",
    "    to_merge = np.logical_and(spatial_overlap, temporal_overlap)\n",
    "    conn_comp = connected_components(to_merge, min_size = 2)\n",
    "    \n",
    "    Anew = A.copy()\n",
    "    Cnew = C.copy()\n",
    "    for comp in tqdm(conn_comp):\n",
    "        merge_idx = comp[0]\n",
    "        \n",
    "        inpA = A[:,:,:,comp]\n",
    "        inpC = C[comp,:]\n",
    "        clique_patch_list = patch_list[comp]\n",
    "        \n",
    "        mergeA, mergeC = merge_component_clique(inpA, inpC, clique_patch_list)\n",
    "        \n",
    "        Anew[:,:,:,comp] = 0\n",
    "        Cnew[comp,:]\n",
    "        \n",
    "        Anew[:,:,:,merge_idx] = mergeA\n",
    "        Cnew[comp,:] = mergeC\n",
    "    \n",
    "        \n",
    "    Anew, Cnew, patch_list = remove_empty_components(Anew, Cnew, patch_list)\n",
    "    \n",
    "    return Anew, Cnew, patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.194552Z",
     "start_time": "2020-08-26T00:30:49.184380Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def merge_component_clique(As, Cs, patch_list):\n",
    "    Ys = []\n",
    "    for idx in np.unique(patch_list):\n",
    "        tempAs = As[:,:,:,patch_list == idx]\n",
    "        tempCs = Cs[patch_list == idx, :]\n",
    "        tempYs = [np.matmul(tempAs[:, :, :, [i]], tempCs[[i], :]) for i in range(tempAs.shape[-1])]\n",
    "        tempY = np.sum(tempYs, 0)\n",
    "        Ys.append(tempY)\n",
    "    \n",
    "    Y = Ys.pop()\n",
    "    Ypos = (np.sum(Y, -1, keepdims = True) > 0).astype('int')\n",
    "\n",
    "    while len(Ys) > 0:\n",
    "        current = Ys.pop()\n",
    "        Y = np.add(Y, current)\n",
    "        Ypos = np.add(Ypos, (np.sum(current, -1, keepdims = True) > 0).astype('int'))\n",
    "    \n",
    "    Ypos[Ypos == 0] = 1\n",
    "    Y = Y/Ypos\n",
    "        \n",
    "    d1,d2,d3, T = Y.shape\n",
    "    Y = np.reshape(Y, (d1*d2*d3, T))\n",
    "    W_init = np.reshape(np.mean(As, 3), (d1*d2*d3, 1))\n",
    "    H_init = np.mean(Cs, 0, keepdims = True)\n",
    "    \n",
    "    A, C, niter = non_negative_factorization(Y, W = W_init, H = H_init, n_components = 1,\n",
    "                    verbose = False, alpha = 0.5, max_iter = 100, tol = 1e-30, init = 'custom')\n",
    "    \n",
    "    A = np.reshape(A, ((d1,d2,d3)))\n",
    "    return A, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.205041Z",
     "start_time": "2020-08-26T00:30:49.196436Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def create_spatial_correlation(A, blur = False, sigma = [0.5,0.5,0.5]):\n",
    "    n_cells = A.shape[-1]\n",
    "    if blur:\n",
    "        A = A.copy()\n",
    "        for i in tqdm(range(n_cells)):\n",
    "            A[:,:,:,i] = gaussian_filter(A[:,:,:,i], sigma, mode = 'constant', output = 'double')\n",
    "    \n",
    "    A = np.reshape(A, (-1, n_cells))\n",
    "\n",
    "    cellsum = np.sum(A, 0, keepdims = True)\n",
    "    A = A / cellsum \n",
    "    \n",
    "    spatial_overlap = np.zeros((n_cells, n_cells))\n",
    "    \n",
    "    for i in tqdm(range(n_cells-1)):\n",
    "        i_pos = A[:, i] > 0\n",
    "        tempA = A[i_pos, :]\n",
    "        subtract_vec = tempA[:, [i]]\n",
    "        tempA = tempA[:, i+1:]\n",
    "        tempA = tempA - subtract_vec\n",
    "        tempA[tempA > 0] = 0\n",
    "        overlap = np.sum(tempA, 0) + 1\n",
    "        spatial_overlap[i, i+1:] = overlap\n",
    "        spatial_overlap[i+1:, i] = overlap\n",
    "            \n",
    "    return spatial_overlap\n",
    "\n",
    "def create_temporal_correlation(C):\n",
    "    return np.abs(np.corrcoef(C)) - np.eye(C.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.216683Z",
     "start_time": "2020-08-26T00:30:49.206893Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def basecall_round(Y, thresh_c, thresh_d, it):\n",
    "    dim,T = Y.shape\n",
    "    if not T == it:\n",
    "        raise Exception('Wrong round dimension...')\n",
    "        \n",
    "    Y = Y.copy().astype('double')\n",
    "    new = np.zeros((dim,T+1)).astype('int')\n",
    "    new[:,0] = (Y[:,0] - thresh_c*Y[:,1]) > 0\n",
    "    new[:,1] = (Y[:,1] - thresh_c*Y[:,0]) > 0\n",
    "    new[:,2] = (Y[:,2] - thresh_d*np.max(Y[:,0:2], 1)) > 0\n",
    "    \n",
    "    new[:, 0] = new[:, 0] - new[:, 2]\n",
    "    new[:, 1] = new[:, 1] - new[:, 2]\n",
    "    \n",
    "    new[new < 0] = 0\n",
    "    \n",
    "    new[:,3] = np.sum(new, 1) == 0\n",
    "    return new\n",
    "\n",
    "def matrix_basecall(Y, thresh_c = 1.5, thresh_d = 1.5, it = 3):\n",
    "    dim,T = Y.shape\n",
    "    basecalls = np.zeros((dim, int(T*(it+1)/it)), dtype = int)\n",
    "    for i in tqdm(range(0, Y.shape[-1], it)):\n",
    "        rd = Y[:,i:i+it]\n",
    "        b_idx = int(i*(it+1)/it)\n",
    "        basecalls[:, b_idx:b_idx+it+1] = basecall_round(rd, thresh_c = thresh_c, thresh_d = thresh_d, it = it)\n",
    "    \n",
    "    return basecalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.222287Z",
     "start_time": "2020-08-26T00:30:49.218521Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_A_pixels(Y, Acomp, percentile = 95):\n",
    "    pos = Acomp[Acomp > 0]\n",
    "    vals = np.where(Acomp > np.percentile(pos, percentile))\n",
    "    \n",
    "    return Y[vals[0], vals[1], vals[2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.232316Z",
     "start_time": "2020-08-26T00:30:49.224061Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def calc_sy(flatY):\n",
    "    dim, T = flatY.shape\n",
    "    n = T\n",
    "    sy = flatY.sum(axis=1, keepdims=True)\n",
    "    sty = np.sqrt(np.sum((flatY - sy/T)**2, 1, keepdims = True) / n)\n",
    "    \n",
    "    return sy, sty\n",
    "\n",
    "def barcode_correlation(X, flatY, sy = None, sty = None):\n",
    "    dim, T = flatY.shape\n",
    "    n = T\n",
    "    if sy is None or sty is None:\n",
    "        sy = flatY.sum(axis=1, keepdims=True)\n",
    "        sty = np.sqrt(np.sum((flatY - sy/T)**2, 1, keepdims = True) / n)\n",
    "    \n",
    "    stx = np.std(X)\n",
    "    sx = np.sum(X)\n",
    "    \n",
    "    corr = (n*np.sum(flatY*X, 1, keepdims = True) - sx*sy) / (n**2 * stx * sty)\n",
    "\n",
    "    corr[np.isnan(corr)] = 0\n",
    "    corr[np.isinf(corr)] = 0\n",
    "    \n",
    "    return corr, sy, sty\n",
    "\n",
    "def barcode_match(barcode, barcode_img, num_bases):\n",
    "    matches = np.dot(barcode_img, barcode.T) == num_bases\n",
    "    return np.squeeze(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.238881Z",
     "start_time": "2020-08-26T00:30:49.234203Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def norm_by_round(vec, bases = 3):\n",
    "    vec = vec.copy()\n",
    "    if(len(vec.shape) == 1):\n",
    "        vec = np.reshape(vec, (1, -1))\n",
    "    for i in range(0, vec.shape[-1], bases):\n",
    "        vec[:, i:i+bases] = vec[:, i:i+bases] / np.max(vec[:, i:i+bases], 1, keepdims = True)\n",
    "    return np.squeeze(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.248792Z",
     "start_time": "2020-08-26T00:30:49.240736Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def duplicate_row(row):\n",
    "    chans = row.shape[0]\n",
    "    val = np.zeros((4, 4*chans))\n",
    "    for i in range(val.shape[0]):\n",
    "        val[i, i*chans:(i+1)*chans] = row\n",
    "    return val\n",
    "\n",
    "def reshape_data_for_optimization(array):\n",
    "    n_pix, n_col = array.shape\n",
    "    array = np.reshape(array, (n_pix, 5, 3))\n",
    "    \n",
    "    array_scaler = np.max(array, -1, keepdims = True)\n",
    "    array_scaler[array_scaler == 0] = 1\n",
    "    \n",
    "    array = array / array_scaler\n",
    "    \n",
    "    dup_array = np.zeros((n_pix, 5, 4, 12))\n",
    "    for pix in range(n_pix):\n",
    "        for r_idx in range(array.shape[1]):\n",
    "            dup_array[pix, r_idx,:, :] = duplicate_row(array[pix, r_idx, :])\n",
    "            \n",
    "    return dup_array\n",
    "\n",
    "def softmax_by_pixel(inp, beta_s = 250):\n",
    "    ex = np.exp(beta_s*inp.astype('float128'))\n",
    "    \n",
    "    bc = ex / np.sum(ex, 2, keepdims = True)\n",
    "    \n",
    "    n_pix = bc.shape[0]\n",
    "    return np.reshape(bc, (n_pix, -1)).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.256336Z",
     "start_time": "2020-08-26T00:30:49.250790Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def center_of_mass_norm(mask, order):\n",
    "    xi, yi, zi = np.where(mask)\n",
    "    center = np.array(center_of_mass(mask))\n",
    "    def loss(center):\n",
    "        xdist = np.sum(np.power(np.abs(xi - center[0]), order))\n",
    "        ydist = np.sum(np.power(np.abs(yi - center[1]), order))\n",
    "        zdist = np.sum(np.power(np.abs(zi - center[2]), order))\n",
    "        return xdist + ydist + zdist\n",
    "    \n",
    "    gradient = grad(loss)\n",
    "    \n",
    "    #print(\"Initial distance:\", loss(center))\n",
    "    for i in range(1000):\n",
    "        #if i % 100 == 0:\n",
    "            #print(\"Current distance:\", loss(center))\n",
    "        \n",
    "        g = gradient(center) \n",
    "        center -= g / (np.linalg.norm(g, 2))\n",
    "        \n",
    "    #print(\"Trained distance:\", loss(center))\n",
    "    return center\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Full Stitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T18:13:33.056141Z",
     "start_time": "2020-08-13T18:13:33.043496Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_fov(filepath, ext = '_affine', raw = False):\n",
    "    num_channels = 3\n",
    "    bases_sequenced = [1, 2, 3, 4, 6]\n",
    "    \n",
    "    if raw:\n",
    "        file_strs = ['ch00', 'ch01', 'ch02']\n",
    "    else:\n",
    "        file_strs = ['ch00', 'ch01SHIFT', 'ch02SHIFT']\n",
    "    filenames = []\n",
    "    for ridx in bases_sequenced:\n",
    "        for fs in file_strs:\n",
    "            filenames.append(filepath+'richieseq_round00'+str(ridx)+'_'+fs+ext+'.tif')\n",
    "\n",
    "    Y = np.array([io.imread(filenames[j]) for j in tqdm(range(len(bases_sequenced)*num_channels))])\n",
    "    Y = np.moveaxis(Y, 1, -1)\n",
    "    Y = np.moveaxis(Y, 0, -1)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T14:08:19.275142Z",
     "start_time": "2020-09-10T14:08:19.271036Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-13T18:25:37.996Z"
    }
   },
   "outputs": [],
   "source": [
    "o_d1, o_d2, o_d3 = 1870, 1946, 400\n",
    "fov_d1, fov_d2, fov_d3 = 1872, 1948, 400\n",
    "full_stitch = np.zeros((fov_d1*7, fov_d2*2, fov_d3, 15), dtype = 'uint16')\n",
    "\n",
    "full_stitch[0*o_d1:(0+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/0_0/2_color-correction/', ext = '')\n",
    "full_stitch[1*o_d1:(1+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/1_0/4_registration/')\n",
    "full_stitch[2*o_d1:(2+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/2_0/4_registration/')\n",
    "full_stitch[3*o_d1:(3+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/3_0/4_registration/')\n",
    "full_stitch[4*o_d1:(4+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/4_0/4_registration/')\n",
    "full_stitch[5*o_d1:(5+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/5_0/4_registration/')\n",
    "full_stitch[6*o_d1:(6+1)*o_d1, 0*o_d2:(0+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/6_0/4_registration/')\n",
    "\n",
    "full_stitch[0*o_d1:(0+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/0_1/2_color-correction/', ext = '')\n",
    "full_stitch[1*o_d1:(1+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/1_1/2_color-correction/', ext = '')\n",
    "full_stitch[2*o_d1:(2+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/2_1/4_registration/')\n",
    "full_stitch[3*o_d1:(3+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/3_1/4_registration/')\n",
    "full_stitch[4*o_d1:(4+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/4_1/4_registration/')\n",
    "full_stitch[5*o_d1:(5+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/5_1/4_registration/')\n",
    "full_stitch[6*o_d1:(6+1)*o_d1, 1*o_d2:(1+1)*o_d2,:,:] = load_fov('/mp/nas2/DG/iarpa_virtual_tiles/6_1/4_registration/')\n",
    "\n",
    "full_stitch = zoom(full_stitch, (0.25, 0.25, 0.25, 1), order = 1)\n",
    "\n",
    "full_stitch_raw = full_stitch\n",
    "\n",
    "full_stitch = high_pass(full_stitch)\n",
    "full_stitch = percentile_normalize(full_stitch)\n",
    "\n",
    "df1,df2,df3,fT = full_stitch.shape\n",
    "fdim = df1*df2*df3\n",
    "flat_full_stitch = np.reshape(full_stitch, (fdim, fT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:58:35.248575Z",
     "start_time": "2020-08-15T16:53:53.215163Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_fov_indices(fov_label):\n",
    "    return [int(val) for val in fov_label.split('_')]\n",
    "\n",
    "fovs = ['0_0', '0_1', '1_0', '1_1', '2_0', '2_1', '3_0', '3_1', '4_0', '4_1', '5_0', '5_1', '6_0', '6_1']\n",
    "\n",
    "Ys = {}\n",
    "fov_d1, fov_d2, fov_d3 = 468, 487, 100\n",
    "\n",
    "for fov in tqdm(fovs):\n",
    "    xf, yf = return_fov_indices(fov)\n",
    "    Ys[fov] = full_stitch_raw[xf*fov_d1:(xf+1)*fov_d1, yf*fov_d2:(yf+1)*fov_d2, :, :]\\\n",
    "    \n",
    "    \n",
    "Ys_raw = Ys\n",
    "\n",
    "for fov in tqdm(As):\n",
    "    Y = Ys[fov]\n",
    "    Y = high_pass(Y)\n",
    "    Y = percentile_normalize(Y)\n",
    "    Ys[fov] = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process NMF patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-14T01:22:00.558Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cells_fov = [0, 0, 5, 0, 15, 15, 15, 15, 15, 15, 15, 15, 0, 0]\n",
    "\n",
    "for fov_idx in range(len(fovs)):\n",
    "    fov_file_label = fovs[fov_idx]\n",
    "    print(fov_file_label)\n",
    "    num_cells = num_cells_fov[fov_idx]\n",
    "    if num_cells == 0:\n",
    "        print('Skipping FOV ' + str(fov_file_label) + '...')\n",
    "    else:\n",
    "        print('Running FOV ' + str(fov_file_label) + '...')\n",
    "        Y = Ys[fov_file_label]\n",
    "        Y = high_pass(Y)\n",
    "        Y = percentile_normalize(Y)\n",
    "\n",
    "        d1,d2,d3,T = Y.shape\n",
    "        dim = d1*d2*d3\n",
    "\n",
    "        flatY = np.reshape(Y, (dim, T))\n",
    "\n",
    "        sigmas = [12,12,8]\n",
    "\n",
    "        patches = create_3D_patches([d1,d2,d3], [150, 150, 100], [30, 30, 30])\n",
    "        num_patches = patches.shape[-1]\n",
    "\n",
    "        A = np.zeros([d1,d2,d3, num_cells*num_patches])\n",
    "        C = np.zeros([num_cells*num_patches, T])\n",
    "        patch_list = np.zeros([num_cells*num_patches])\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # ignore all caught warnings\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "            for i in tqdm(range(num_patches)):\n",
    "                idx = i*num_cells\n",
    "                patch_coords = patches[:,:,i]\n",
    "                x1,y1,z1,x2,y2,z2 = np.ravel(patch_coords)\n",
    "                Ypatch = Y[x1:x2, y1:y2, z1:z2, :]\n",
    "                pl = np.array([i]*num_cells)\n",
    "                Apatch, Cpatch, pl = process_patch(Ypatch, num_cells, sigmas, pl)\n",
    "\n",
    "                merged_num = Cpatch.shape[0]\n",
    "                print('Reshaping patch results...')\n",
    "                patch_list[idx:idx+merged_num] = pl\n",
    "                C[idx:idx+merged_num] = Cpatch\n",
    "                A[:,:,:,idx:idx+merged_num] = embed_patch_results(Apatch, [d1,d2,d3], [x1,y1,z1], [x2, y2, z2])\n",
    "\n",
    "        A, C, patch_list = remove_empty_components(A, C, patch_list)\n",
    "        A, C, patch_list = merge_components(A, C, patch_list)\n",
    "\n",
    "        pickle.dump(A, open(fov_file_label+\"reprocess_complete_A.p\", \"wb\" ))\n",
    "        pickle.dump(C, open(fov_file_label+\"reprocess_complete_C.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:45:40.376150Z",
     "start_time": "2020-08-26T00:41:58.085430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d373d12d494a24a6f0f0b047f94bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No components loaded for 0_1\n",
      "No components loaded for 1_1\n",
      "No components loaded for 6_0\n",
      "No components loaded for 6_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fovs = ['0_0', '0_1', '1_0', '1_1', '2_0', '2_1', '3_0', '3_1', '4_0', '4_1', '5_0', '5_1', '6_0', '6_1']\n",
    "\n",
    "As = {}\n",
    "Cs = {}\n",
    "\n",
    "for fov in tqdm(fovs):\n",
    "    try:\n",
    "        As[fov] = pickle.load(open(fov+\"_A.p\", \"rb\" ))\n",
    "        Cs[fov] = pickle.load(open(fov+\"_C.p\", \"rb\" ))\n",
    "    except:\n",
    "        print('No components loaded for ' + fov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:45:40.397151Z",
     "start_time": "2020-08-26T00:45:40.379502Z"
    }
   },
   "outputs": [],
   "source": [
    "fov_list = []\n",
    "for fov in fovs:\n",
    "    if fov in As:\n",
    "        fov_list = fov_list + [fov] * As[fov].shape[-1]\n",
    "        \n",
    "fov_list = np.array(fov_list)\n",
    "\n",
    "padding = {}\n",
    "full_padding = {}\n",
    "ffv1, ffv2, ffv3 = 1870, 1946, 400\n",
    "fv1, fv2, fv3 = 468, 486, 100\n",
    "for fov in fovs:\n",
    "    full_padding[fov] = np.array((int(fov[0])*ffv1, int(fov[2])*ffv2, 0))\n",
    "    padding[fov] = np.array((int(fov[0])*fv1, int(fov[2])*fv2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T01:59:26.219365Z",
     "start_time": "2020-08-26T00:45:40.399780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceb9f204b20483a9c040c4a8564f988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664c8331c6df450ea11d259ac903b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73531c27e1b441386945c4ea98281a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de211b02313d41dba2ef87405933f54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=121.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axue/miniconda3/envs/seq/lib/python3.8/site-packages/autograd/numpy/numpy_vjps.py:59: RuntimeWarning: divide by zero encountered in power\n",
      "  lambda ans, x, y : unbroadcast_f(x, lambda g: g * y * x ** anp.where(y, y - 1, 1.)),\n",
      "/home/axue/miniconda3/envs/seq/lib/python3.8/site-packages/autograd/numpy/numpy_vjps.py:71: RuntimeWarning: invalid value encountered in multiply\n",
      "  lambda ans, x : lambda g: g * replace_zero(anp.conj(x), 0.) / replace_zero(ans, 1.))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc09fbe620e41af870f258ec0bb2c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b307a2e9feb4357a16b5e1d136275cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc00eaf5a7b49e4bac45a05b338ff9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d116d81068a4a4a93f99ee8da885a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=126.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd6609e58c34ea89f8731bee32d2d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5601da34cf241ffb35022b59f50959b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebabf8415994cb08ac503c5011e1f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf_distances = []\n",
    "nmf_coms = []\n",
    "nmf_df = []\n",
    "\n",
    "for fov in tqdm(fovs):\n",
    "    if fov in As:\n",
    "        A = As[fov]\n",
    "        for cidx in tqdm(range(A.shape[-1])):\n",
    "            comp = A[:,:,:,cidx]\n",
    "            high = comp > np.percentile(comp, 99.99)\n",
    "            comr = center_of_mass_norm(high, 0.5)\n",
    "            x,y,z = comr\n",
    "            xpos, ypos, zpos = np.where(high)\n",
    "\n",
    "            distance = []\n",
    "            for idx in range(xpos.shape[-1]):\n",
    "                dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "                distance.append(dist ** 0.5)\n",
    "            nmf_distances.append(distance)\n",
    "\n",
    "            df = np.sum(dilation(high, ball(1))) / np.sum(high)\n",
    "            nmf_df.append(df)\n",
    "\n",
    "            com = comr + padding[fov]\n",
    "            nmf_coms.append(com)\n",
    "            \n",
    "nmf_median_distances = np.array([np.median(distances) for distances in nmf_distances])\n",
    "\n",
    "nmf_coms = np.array(nmf_coms)\n",
    "nmf_df = np.array(nmf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T01:59:26.255130Z",
     "start_time": "2020-08-26T01:59:26.229269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-b8b3b6fa1a3e>:1: RuntimeWarning: invalid value encountered in less\n",
      "  prefilter = np.logical_and(nmf_median_distances < 50, nmf_df < 5)\n"
     ]
    }
   ],
   "source": [
    "prefilter = np.logical_and(nmf_median_distances < 50, nmf_df < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T01:59:26.263050Z",
     "start_time": "2020-08-26T01:59:26.256272Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fov_index(fov_list, idx):\n",
    "    fov_label = fov_list[idx]\n",
    "    start_idx = np.where(fov_list == fov_label)[0][0]\n",
    "    new_idx = idx - start_idx\n",
    "    return fov_label, new_idx\n",
    "\n",
    "def get_fov_index_dict(fov_list, idx_list):\n",
    "    return_dict = {}\n",
    "    for idx in idx_list:\n",
    "        fov_label, new_idx = get_fov_index(fov_list, idx)\n",
    "        if fov_label in return_dict:\n",
    "            return_dict[fov_label].append(new_idx)\n",
    "        else:\n",
    "            return_dict[fov_label] = [new_idx]\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T01:59:26.508986Z",
     "start_time": "2020-08-26T01:59:26.264164Z"
    }
   },
   "outputs": [],
   "source": [
    "fullC = np.concatenate([Cs[fov] for fov in fovs if fov in Cs], 0)\n",
    "tc = create_temporal_correlation(fullC)\n",
    "pm = patch_mismatch(fov_list)\n",
    "comd = cdist(nmf_coms, nmf_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T02:00:28.291288Z",
     "start_time": "2020-08-26T01:59:26.510415Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-55253d412b9d>:1: RuntimeWarning: invalid value encountered in less\n",
      "  merge_across_patches = connected_components(np.logical_and(np.logical_and(comd < 90, pm), tc > 0.85), 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4676e1a7f82a40c2987afa55fa94279b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "merge_across_patches = connected_components(np.logical_and(np.logical_and(comd < 90, pm), tc > 0.85), 2)\n",
    "\n",
    "remove_indices = []\n",
    "for cc in tqdm(merge_across_patches):\n",
    "    cc_sizes = [np.sum(As[get_fov_index(fov_list, elm)[0]][:,:,:,get_fov_index(fov_list, elm)[1]]) for elm in cc]\n",
    "    [remove_indices.append(index) for index in cc if index != cc[np.argmax(cc_sizes)]]\n",
    "    \n",
    "prefilter[remove_indices] = False\n",
    "\n",
    "prefilter = np.where(prefilter)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T02:07:13.478337Z",
     "start_time": "2020-08-26T02:00:28.293638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86993393881a461dad0c6d30e793a096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keep_dict = get_fov_index_dict(fov_list,prefilter)\n",
    "fov_list = fov_list[prefilter]\n",
    "\n",
    "for fov in tqdm(fovs):\n",
    "    if fov in As:\n",
    "        As[fov] = As[fov][:,:,:, keep_dict[fov]]\n",
    "        Cs[fov] = Cs[fov][keep_dict[fov], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T02:19:08.114624Z",
     "start_time": "2020-08-26T02:19:08.105065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T17:01:21.222166Z",
     "start_time": "2020-08-15T16:58:35.250781Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make input data for training\n",
    "num_pixels = 1000\n",
    "inputs = []\n",
    "cross_comp_vals = []\n",
    "\n",
    "for fov in fovs:\n",
    "    if fov in As:\n",
    "        A = As[fov]\n",
    "        Y = Ys[fov]\n",
    "        C = Cs[fov]\n",
    "        \n",
    "        selected_components = range(A.shape[-1])\n",
    "        for fidx in tqdm(selected_components):\n",
    "            input_vals = []\n",
    "            mask = A[:,:,:, fidx] > np.percentile(A[:,:,:, fidx], 99.99)\n",
    "            masked = Y[mask, :]\n",
    "\n",
    "            input_vals.append(reshape_data_for_optimization(masked[np.random.choice(masked.shape[0], size=num_pixels, replace = False), :]))    \n",
    "            inputs.append(input_vals)\n",
    "\n",
    "            cross_comp_vals.append(masked[np.random.choice(masked.shape[0], size=num_pixels, replace = False), :])\n",
    "\n",
    "\n",
    "cross_comp_vals = np.concatenate(cross_comp_vals, 0)\n",
    "\n",
    "idx = 0\n",
    "for fov in fovs:\n",
    "    if fov in As:\n",
    "        A = As[fov]\n",
    "        Y = Ys[fov]\n",
    "        C = Cs[fov]\n",
    "        selected_components = range(A.shape[-1])\n",
    "        \n",
    "        for fidx in tqdm(selected_components):\n",
    "            inputs[idx].append(reshape_data_for_optimization(cross_comp_vals[np.random.choice(cross_comp_vals.shape[0], size=num_pixels, replace = False), :]))\n",
    "            inputs[idx].append(reshape_data_for_optimization(C[[fidx], :]))\n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T23:24:51.420787Z",
     "start_time": "2020-08-15T17:01:21.224161Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]]).astype('d')\n",
    "matrix_gradient = grad(basecalling_loss)\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "training_steps = [500, 500, 500]\n",
    "print(\"Initial loss:\", basecalling_loss(weights))\n",
    "for train_idx in range(len(learning_rates)):\n",
    "    for i in tqdm(range(training_steps[train_idx])):\n",
    "        if i % 10 == 0:\n",
    "            print(\"Current loss:\", basecalling_loss(weights))\n",
    "        weights -= matrix_gradient(weights) * learning_rates[train_idx]\n",
    "\n",
    "print(\"Trained loss:\", basecalling_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.262323Z",
     "start_time": "2020-08-26T00:30:49.258251Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def basecall_with_weights(Y, rweights):\n",
    "    d1, d2, d3, T = Y.shape\n",
    "    barcodeY = np.reshape(Y, (d1, d2, d3, 5, 3))\n",
    "    barcodeY = np.matmul(barcodeY, rweights.T)\n",
    "    barcodeY = (barcodeY / np.max(barcodeY, -1, keepdims = True) == 1).astype('int')\n",
    "    barcodeY = np.reshape(barcodeY, (d1,d2,d3, -1))\n",
    "    return barcodeY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T06:26:28.040531Z",
     "start_time": "2020-08-17T06:20:04.215345Z"
    }
   },
   "outputs": [],
   "source": [
    "rweights = np.reshape(weights, (4,3))\n",
    "\n",
    "d1, d2, d3, T = full_stitch.shape\n",
    "barcodeY = np.reshape(flat_full_stitch, (d1, d2, d3, 5, 3))\n",
    "barcodeY = np.matmul(barcodeY, rweights.T)\n",
    "barcodeY = (barcodeY / np.max(barcodeY, -1, keepdims = True) == 1).astype('int')\n",
    "barcodeY = np.reshape(barcodeY, (d1,d2,d3, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T03:33:01.412653Z",
     "start_time": "2020-08-26T03:33:01.273711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86f5a3c8d524ab785051ad8255a8bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-059872d5ce46>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  barcodeC = (barcodeC / np.max(barcodeC, -1, keepdims = True) == 1).astype('int')\n"
     ]
    }
   ],
   "source": [
    "rweights = np.reshape(weights, (4,3))\n",
    "\n",
    "fullC = []\n",
    "full_barcodeC = []\n",
    "barcodeCs = {}\n",
    "for fov in tqdm(fovs):\n",
    "    if fov in Cs:\n",
    "        C = Cs[fov]\n",
    "        b1, bT = C.shape\n",
    "        barcodeC = np.reshape(C, (b1, 5, 3))\n",
    "        barcodeC = np.matmul(barcodeC, rweights.T)\n",
    "        barcodeC = (barcodeC / np.max(barcodeC, -1, keepdims = True) == 1).astype('int')\n",
    "        barcodeC = np.reshape(barcodeC, (b1,-1))\n",
    "        barcodeCs[fov] = barcodeC\n",
    "        fullC.append(C)\n",
    "        full_barcodeC.append(barcodeC)\n",
    "        \n",
    "fullC = np.concatenate(fullC, 0)\n",
    "full_barcodeC = np.concatenate(full_barcodeC, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T06:26:28.109063Z",
     "start_time": "2020-08-17T06:26:28.102329Z"
    }
   },
   "outputs": [],
   "source": [
    "un, inv, cts = np.unique(full_barcodeC, axis = 0, return_counts = True, return_inverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T07:41:38.139878Z",
     "start_time": "2020-08-17T06:26:28.111267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_vals = []\n",
    "y_size = []\n",
    "y_dilation_factor = []\n",
    "y_distances = []\n",
    "\n",
    "for fov in tqdm(fovs):\n",
    "    if fov in As:\n",
    "        Y = Ys[fov]\n",
    "        A = As[fov]\n",
    "        C = Cs[fov]\n",
    "        barcodeC = barcodeCs[fov]\n",
    "        \n",
    "        dy1, dy2, dy3, T = Y.shape\n",
    "        flatY = np.reshape(Y, (dy1*dy2*dy3, T))\n",
    "        barcodeYs = basecall_with_weights(Y, rweights)\n",
    "        \n",
    "        sy, sty = calc_sy(flatY)\n",
    "        \n",
    "        for idx in tqdm(range(A.shape[-1])):\n",
    "            bm = barcode_match(barcodeC[idx, :], barcodeYs, 5)\n",
    "            corr, sy, sty = barcode_correlation(C[idx,:], flatY, sy, sty)\n",
    "            corr = np.reshape(corr, (dy1,dy2,dy3))\n",
    "            merged = np.logical_and(bm, corr > 0.75)\n",
    "            sens = (np.sum(A[merged,idx]) / np.sum(A[:,:,:,idx]))\n",
    "            spec = (np.sum(merged)/merged.size)\n",
    "            y_vals.append(sens/spec)\n",
    "            y_size.append(np.sum(merged))\n",
    "            y_dilation_factor.append(np.sum(dilation(merged, ball(1))) / np.sum(merged))\n",
    "\n",
    "            x,y,z = center_of_mass_norm(merged, 0.5)\n",
    "            xpos, ypos, zpos = np.where(merged > 0)\n",
    "\n",
    "            distance = []\n",
    "            for idx in range(xpos.shape[-1]):\n",
    "                dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "                distance.append(dist ** 0.5)\n",
    "            y_distances.append(distance)\n",
    "            \n",
    "y_vals = np.array(y_vals)\n",
    "y_size = np.array(y_size)\n",
    "y_dilation_factor = np.array(y_dilation_factor)\n",
    "y_median_distances = np.array([np.median(distance) for distance in y_distances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T07:41:38.147484Z",
     "start_time": "2020-08-17T07:41:38.141933Z"
    }
   },
   "outputs": [],
   "source": [
    "size_filter = np.logical_and(y_size > 1000, y_size < 100000)\n",
    "dilation_filter = y_dilation_factor < 5\n",
    "enrichment_filter = y_vals > 50\n",
    "distance_filter = y_median_distances < 100\n",
    "\n",
    "filtered_idx = np.where(np.logical_and(np.logical_and(size_filter, dilation_filter), np.logical_and(enrichment_filter, distance_filter)))[0]\n",
    "\n",
    "print(filtered_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T07:43:42.051897Z",
     "start_time": "2020-08-17T07:41:38.148676Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_factor = 2\n",
    "\n",
    "ds_full_stitch = zoom(full_stitch, (1/ds_factor, 1/ds_factor, 1/ds_factor, 1), order = 1)\n",
    "ds1, ds2, ds3, T = ds_full_stitch.shape\n",
    "ds_flat_full_stitch = np.reshape(ds_full_stitch, (ds1*ds2*ds3, T))\n",
    "barcodeYds = basecall_with_weights(ds_full_stitch, rweights)\n",
    "\n",
    "sy, sty = calc_sy(ds_flat_full_stitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:15:34.938631Z",
     "start_time": "2020-08-17T07:43:42.053900Z"
    }
   },
   "outputs": [],
   "source": [
    "barcode_duplicate_thresh = 5\n",
    "\n",
    "labels = np.zeros(ds_full_stitch.shape[0:3])\n",
    "dsfv1, dsfv2, dsfv3 = fv1//ds_factor, fv2//ds_factor, fv3//ds_factor\n",
    "ds_padding = {}\n",
    "for fov in padding:\n",
    "    ds_padding[fov] = padding[fov] // ds_factor\n",
    "\n",
    "already_processed = set()\n",
    "d1,d2,d3,T = ds_full_stitch.shape\n",
    "\n",
    "vals = np.zeros(fullC.shape[0])\n",
    "size = np.zeros(fullC.shape[0])\n",
    "dilation_factor = np.zeros(fullC.shape[0])\n",
    "distances = [[] for comp in range(fullC.shape[0])]\n",
    "inpatch = np.zeros(fullC.shape[0])\n",
    "\n",
    "for component_idx in tqdm(filtered_idx):\n",
    "    if component_idx not in already_processed:\n",
    "        matching_idx = np.where(inv == inv[component_idx])[0]\n",
    "        if len(matching_idx) <= barcode_duplicate_thresh:\n",
    "            d1,d2,d3,T = ds_full_stitch.shape\n",
    "            bm = barcode_match(full_barcodeC[component_idx, :], barcodeYds, 5)\n",
    "\n",
    "            corrs = []\n",
    "            for match_idx in matching_idx:\n",
    "                corr, sy, sty = barcode_correlation(fullC[match_idx,:], ds_flat_full_stitch, sy, sty)\n",
    "                corr = np.reshape(corr, (d1,d2,d3))\n",
    "                corrs.append(corr)\n",
    "            \n",
    "            corrs = np.stack(corrs, -1)\n",
    "            for c_idx in range(len(matching_idx)):\n",
    "                match_idx = matching_idx[c_idx]\n",
    "                corr_mask = np.logical_and(corrs[:,:,:,c_idx] > 0.75, corrs[:,:,:,c_idx] == np.max(corrs, -1))\n",
    "                merged = np.logical_and(bm, corr_mask)\n",
    "\n",
    "                fov, fov_index = get_fov_index(fov_list, match_idx)\n",
    "                p1, p2, p3 = ds_padding[fov].astype('int')\n",
    "                A_ds = zoom(As[fov][:,:,:,fov_index], (1/ds_factor, 1/ds_factor, 1/ds_factor), order = 1)\n",
    "\n",
    "                merged_single_fov = merged[p1:p1+A_ds.shape[0], p2:p2+A_ds.shape[1], p3:p3+A_ds.shape[2]]\n",
    "                \n",
    "                sens = (np.sum(A_ds[merged_single_fov]) / np.sum(A_ds))\n",
    "                spec = (np.sum(merged_single_fov)/merged_single_fov.size)\n",
    "                vals[match_idx] = (sens/spec)\n",
    "                size[match_idx] = (np.sum(merged))\n",
    "                inpatch[match_idx] = np.sum(merged_single_fov) / np.sum(merged)\n",
    "                dilation_factor[match_idx] = (np.sum(dilation(merged, ball(1))) / np.sum(merged))\n",
    "\n",
    "                x,y,z = center_of_mass_norm(merged, 0.5)\n",
    "                xpos, ypos, zpos = np.where(merged > 0)\n",
    "                \n",
    "                if match_idx in filtered_idx:\n",
    "                    labels[merged] = match_idx\n",
    "                \n",
    "                distance = []\n",
    "                for idx in range(xpos.shape[-1]):\n",
    "                    dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "                    distance.append(dist ** 0.5)\n",
    "                distances[match_idx] = (distance)\n",
    "                \n",
    "                already_processed.add(match_idx)\n",
    "                \n",
    "median_distances = np.array([np.median(distance) for distance in distances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T08:15:34.943818Z",
     "start_time": "2020-08-17T08:15:34.941048Z"
    }
   },
   "outputs": [],
   "source": [
    "inpatch_threshold = 0.4\n",
    "final_idx = filtered_idx[inpatch[filtered_idx] > inpatch_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Image Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T19:12:16.955325Z",
     "start_time": "2020-08-17T16:50:48.769727Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_cvec = []\n",
    "good_barcode = []\n",
    "\n",
    "d1,d2,d3,T = full_stitch.shape\n",
    "full_stitch_labels = np.zeros((d1,d2,d3))\n",
    "sy, sty = calc_sy(flat_full_stitch)\n",
    "fv1, fv2, fv3 = 468, 487, 100\n",
    "\n",
    "already_processed = set()\n",
    "\n",
    "for component_idx in tqdm(final_idx):\n",
    "    if component_idx not in already_processed:\n",
    "        matching_idx = np.where(inv == inv[component_idx])[0]\n",
    "        bm = barcode_match(full_barcodeC[component_idx, :], barcodeY, 5)\n",
    "\n",
    "        corrs = []\n",
    "        for match_idx in matching_idx:\n",
    "            corr, sy, sty = barcode_correlation(fullC[match_idx,:], flat_full_stitch, sy, sty)\n",
    "            corr = np.reshape(corr, (d1,d2,d3))\n",
    "            corrs.append(corr)\n",
    "\n",
    "        corrs = np.stack(corrs, -1)\n",
    "        for c_idx in range(len(matching_idx)):\n",
    "            match_idx = matching_idx[c_idx]\n",
    "            corr_mask = np.logical_and(corrs[:,:,:,c_idx] > 0.75, corrs[:,:,:,c_idx] == np.max(corrs, -1))\n",
    "            merged = np.logical_and(bm, corr_mask)\n",
    "\n",
    "            if match_idx in final_idx:\n",
    "                full_stitch_labels[merged] = match_idx\n",
    "                good_cvec.append(fullC[match_idx, :])\n",
    "                good_barcode.append(full_barcodeC[match_idx,:])\n",
    "\n",
    "            already_processed.add(match_idx)\n",
    "            \n",
    "good_cvec = np.array(good_cvec)\n",
    "good_barcode = np.array(good_barcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:31:29.484302Z",
     "start_time": "2020-08-18T04:29:45.529939Z"
    }
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(upsample_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "plt.figure(figsize=(25,70))\n",
    "plt.imshow(col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T19:29:05.485739Z",
     "start_time": "2020-08-17T19:28:57.188082Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(full_stitch_labels, open(\"full_stitch_label_reprocess_complete.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T19:44:44.418072Z",
     "start_time": "2020-08-17T19:36:53.052029Z"
    }
   },
   "outputs": [],
   "source": [
    "upsample_labels = zoom(full_stitch_labels, (4,4,4), order = 0).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:40:28.576144Z",
     "start_time": "2020-08-18T04:40:25.052272Z"
    }
   },
   "outputs": [],
   "source": [
    "f1,f2,f3 = 13090, 3892, 400\n",
    "final_labels = upsample_labels[:f1, :f2, :f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:58:36.466555Z",
     "start_time": "2020-08-06T17:58:04.581121Z"
    }
   },
   "outputs": [],
   "source": [
    "f1,f2,f3 = 13090, 3892, 400\n",
    "resized_labels = np.zeros((f1+50, f2+50, f3+50), dtype = 'uint16')\n",
    "l1,l2,l3 = upsample_labels.shape\n",
    "resized_labels[:l1, :l2, :l3] = upsample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:59:33.441645Z",
     "start_time": "2020-08-06T17:58:36.468729Z"
    }
   },
   "outputs": [],
   "source": [
    "ffv1, ffv2, ffv3 = 1870, 1946, 400\n",
    "horizontal_patches = 2\n",
    "vertical_patches = 7\n",
    "\n",
    "imagestack = []\n",
    "\n",
    "for h in tqdm(range(horizontal_patches)):\n",
    "    column = []\n",
    "    for v in tqdm(range(vertical_patches)):\n",
    "        column.append(resized_labels[v*ffv1:(v+1)*ffv1, h*ffv2:(h+1)*ffv2,:ffv3])\n",
    "    imagestack.append(np.concatenate(column, 0))\n",
    "final_labels = np.concatenate(imagestack, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T20:31:43.712760Z",
     "start_time": "2020-08-11T20:31:43.703877Z"
    }
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T20:25:46.087514Z",
     "start_time": "2020-08-11T20:25:06.448191Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(final_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "plt.figure(figsize=(25,70))\n",
    "plt.imshow(col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T04:41:01.047Z"
    }
   },
   "outputs": [],
   "source": [
    "io.imsave('/mp/nas2/axue/fullstitch_components_no_offset.tif', final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T19:49:53.372253Z",
     "start_time": "2020-08-17T19:44:44.430206Z"
    }
   },
   "outputs": [],
   "source": [
    "io.imsave('/mp/nas2/axue/fullstitch_components_reprocess_complete.tif', final_labels)\n",
    "np.savetxt('/mp/nas2/axue/fullstitch_barcode_reprocess_complete.csv', good_barcode, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/fullstitch_Cvec_reprocess_complete.csv', good_cvec, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T16:51:16.627768Z",
     "start_time": "2020-07-21T16:51:16.620688Z"
    }
   },
   "outputs": [],
   "source": [
    "final_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T16:59:23.883455Z",
     "start_time": "2020-07-21T16:59:19.123416Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 35))\n",
    "plt.imshow(np.sum(full_stitch, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T16:53:45.394572Z",
     "start_time": "2020-07-21T16:53:26.088545Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,35))\n",
    "plt.imshow(np.sum(gaussian_filter(full_stitch_labels == 589, [4, 4, 1], mode = 'constant', output = 'double'), (2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_colors = color.label2rgb(final_idx)\n",
    "\n",
    "labels2 = np.max(full_stitch_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "match = np.max(full_stitch_labels == idx, 2)\n",
    "sub_labels = col_labels\n",
    "sub_labels[~match, :] = 0\n",
    "sub_labels[match, :] = idx_colors[np.where(final_idx == idx)[0][0]]\n",
    "plt.figure(figsize=(25,70))\n",
    "plt.imshow(sub_labels)\n",
    "plt.savefig('fullstitch/'+str(idx)+'_fullstitch_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T19:01:22.107012Z",
     "start_time": "2020-07-15T18:57:12.444513Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in tqdm(final_idx):\n",
    "\n",
    "    idx_colors = color.label2rgb(final_idx)\n",
    "\n",
    "    labels2 = np.max(full_stitch_labels, 2)\n",
    "    col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "    match = np.max(full_stitch_labels == idx, 2)\n",
    "    sub_labels = col_labels\n",
    "    sub_labels[~match, :] = 0\n",
    "    sub_labels[match, :] = idx_colors[np.where(final_idx == idx)[0][0]]\n",
    "    plt.figure(figsize=(25,70))\n",
    "    plt.imshow(sub_labels)\n",
    "    plt.savefig('fullstitch/'+str(idx)+'_fullstitch_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:55:01.521474Z",
     "start_time": "2020-07-15T17:54:23.426957Z"
    }
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(full_stitch_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "plt.figure(figsize=(25,70))\n",
    "plt.imshow(col_labels)\n",
    "plt.savefig('fullstitch_components.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Optimization Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T00:30:49.270050Z",
     "start_time": "2020-08-26T00:30:49.264479Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def basecalling_loss(weights, alpha = 1, beta = 4, gamma = 0.1):\n",
    "    loss = 0\n",
    "    for i in range(len(inputs)):\n",
    "        inpA = inputs[i][0] \n",
    "        inpB = inputs[i][1] \n",
    "        inpC = inputs[i][2]\n",
    "        bA = softmax_by_pixel(np.matmul(inpA, weights.T)) \n",
    "        bB = softmax_by_pixel(np.matmul(inpB, weights.T))\n",
    "        bC = softmax_by_pixel(np.matmul(inpC, weights.T))\n",
    "        #variance_loss = -np.mean(np.matmul(bA, bA.T)) \n",
    "        variance_loss = -np.mean(np.matmul(bA, bC.T)) \n",
    "        discrimination_loss = np.mean(np.matmul(bA, bB.T)) \n",
    "        \n",
    "        loss += (alpha*variance_loss + beta*discrimination_loss)/len(inputs)\n",
    "    \n",
    "    loss += gamma * np.sum(weights ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Image Discrimination Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make input data for training\n",
    "num_pixels = 500\n",
    "inputs = []\n",
    "selected_components = range(A.shape[-1])\n",
    "for idx in tqdm(selected_components):\n",
    "    input_vals = []\n",
    "    mask = A[:,:,:, idx] > np.percentile(A[:,:,:, idx], 99.99)\n",
    "    masked = Y[mask, :]\n",
    "    \n",
    "    input_vals.append(reshape_data_for_optimization(masked[np.random.randint(masked.shape[0], size=num_pixels), :]))\n",
    "    \n",
    "    pos_mask = np.sum(Y, -1) > 0\n",
    "    pos_masked = Y[pos_mask, :]\n",
    "    input_vals.append(reshape_data_for_optimization(pos_masked[np.random.randint(pos_masked.shape[0], size=num_pixels), :]))\n",
    "    \n",
    "    input_vals.append(reshape_data_for_optimization(C[[idx], :]))\n",
    "    \n",
    "    inputs.append(input_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Component Discrimination Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T04:34:52.492540Z",
     "start_time": "2020-07-07T04:34:04.475437Z"
    }
   },
   "outputs": [],
   "source": [
    "#make input data for training\n",
    "num_pixels = 500\n",
    "inputs = []\n",
    "cross_comp_vals = []\n",
    "selected_components = range(A.shape[-1])\n",
    "for idx in tqdm(selected_components):\n",
    "    input_vals = []\n",
    "    mask = A[:,:,:, idx] > np.percentile(A[:,:,:, idx], 99.99)\n",
    "    masked = Y[mask, :]\n",
    "    \n",
    "    input_vals.append(reshape_data_for_optimization(masked[np.random.choice(masked.shape[0], size=num_pixels, replace = False), :]))    \n",
    "    inputs.append(input_vals)\n",
    "    \n",
    "    cross_comp_vals.append(masked[np.random.choice(masked.shape[0], size=num_pixels, replace = False), :])\n",
    "\n",
    "\n",
    "cross_comp_vals = np.concatenate(cross_comp_vals, 0)\n",
    "    \n",
    "for idx in tqdm(selected_components):\n",
    "    inputs[idx].append(reshape_data_for_optimization(cross_comp_vals[np.random.choice(cross_comp_vals.shape[0], size=num_pixels, replace = False), :]))\n",
    "    inputs[idx].append(reshape_data_for_optimization(C[[idx], :]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization over All Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:35:31.792492Z",
     "start_time": "2020-07-07T15:56:25.294046Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]]).astype('d')\n",
    "matrix_gradient = grad(basecalling_loss)\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "training_steps = [500, 500, 500]\n",
    "print(\"Initial loss:\", basecalling_loss(weights))\n",
    "for train_idx in range(len(learning_rates)):\n",
    "    for i in tqdm(range(training_steps[train_idx])):\n",
    "        if i % 10 == 0:\n",
    "            print(\"Current loss:\", basecalling_loss(weights))\n",
    "        weights -= matrix_gradient(weights) * learning_rates[train_idx]\n",
    "\n",
    "print(\"Trained loss:\", basecalling_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:43:36.853351Z",
     "start_time": "2020-07-07T16:37:28.743605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rweights = np.reshape(weights, (4,3))\n",
    "\n",
    "dy1, dy2, dy3, T = Y.shape\n",
    "barcodeYs = np.reshape(Y, (dy1, dy2, dy3, 5, 3))\n",
    "barcodeYs = np.matmul(barcodeYs, rweights.T)\n",
    "barcodeYs = (barcodeYs / np.max(barcodeYs, -1, keepdims = True) == 1).astype('int')\n",
    "barcodeYs = np.reshape(barcodeYs, (d1,d2,d3, -1))\n",
    "\n",
    "d1, d2, d3, T = full_stitch.shape\n",
    "barcodeY = np.reshape(flat_full_stitch, (d1, d2, d3, 5, 3))\n",
    "barcodeY = np.matmul(barcodeY, rweights.T)\n",
    "barcodeY = (barcodeY / np.max(barcodeY, -1, keepdims = True) == 1).astype('int')\n",
    "barcodeY = np.reshape(barcodeY, (d1,d2,d3, -1))\n",
    "\n",
    "b1, bT = C.shape\n",
    "barcodeC = np.reshape(C, (b1, 5, 3))\n",
    "barcodeC = np.matmul(barcodeC, rweights.T)\n",
    "barcodeC = (barcodeC / np.max(barcodeC, -1, keepdims = True) == 1).astype('int')\n",
    "barcodeC = np.reshape(barcodeC, (b1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:13:39.050340Z",
     "start_time": "2020-07-15T04:13:39.043967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(filtered_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:15:13.730251Z",
     "start_time": "2020-07-15T04:15:05.198060Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d1,d2,d3,T = ds_full_stitch.shape\n",
    "idx = 40\n",
    "bm = barcode_match(full_barcodeC[idx, :], barcodeYds, 5)\n",
    "corr, sy, sty = barcode_correlation(fullC[idx,:], ds_flat_full_stitch, sy, sty)\n",
    "corr = np.reshape(corr, (d1,d2,d3))\n",
    "merged = np.logical_and(bm, corr > 0.75)\n",
    "viewmask(merged)\n",
    "\n",
    "print(np.sum(merged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T15:53:47.925972Z",
     "start_time": "2020-07-07T15:37:05.518533Z"
    }
   },
   "outputs": [],
   "source": [
    "d1,d2,d3,T = Y.shape\n",
    "\n",
    "vals = []\n",
    "size = []\n",
    "dilation_factor = []\n",
    "distances = []\n",
    "for idx in tqdm(range(A.shape[-1])):\n",
    "    bm = barcode_match(barcodeC[idx, :], barcodeYs, 5)\n",
    "    corr, sy, sty = barcode_correlation(C[idx,:], flatY, sy, sty)\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    merged = np.logical_and(bm, corr > 0.75)\n",
    "    sens = (np.sum(A[merged,idx]) / np.sum(A[:,:,:,idx]))\n",
    "    spec = (np.sum(merged)/merged.size)\n",
    "    vals.append(sens/spec)\n",
    "    size.append(np.sum(merged))\n",
    "    dilation_factor.append(np.sum(dilation(merged, ball(1))) / np.sum(merged))\n",
    "    \n",
    "    x,y,z = center_of_mass_norm(merged, 0.5)\n",
    "    xpos, ypos, zpos = np.where(merged > 0)\n",
    "\n",
    "    distance = []\n",
    "    for idx in range(xpos.shape[-1]):\n",
    "        dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "        distance.append(dist ** 0.5)\n",
    "    distances.append(distance)\n",
    "\n",
    "vals = np.array(vals)\n",
    "size = np.array(size)\n",
    "dilation_factor = np.array(dilation_factor)\n",
    "\n",
    "median_distances = np.array([np.median(dist_arr) for dist_arr in distances])\n",
    "\n",
    "size_filter = np.logical_and(size > 1000, size < 100000)\n",
    "dilation_filter = dilation_factor < 5\n",
    "enrichment_filter = vals > 50\n",
    "distance_filter = median_distances < 100\n",
    "\n",
    "filtered_idx = np.where(np.logical_and(np.logical_and(size_filter, dilation_filter), np.logical_and(enrichment_filter, distance_filter)))[0]\n",
    "\n",
    "print(filtered_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T16:21:42.634867Z",
     "start_time": "2020-07-08T15:56:11.153645Z"
    }
   },
   "outputs": [],
   "source": [
    "d1,d2,d3, T = full_stitch.shape\n",
    "dy1, dy2, dy3, T = Y.shape\n",
    "\n",
    "fovx, fovy = 3, 1\n",
    "inpatch_thresh = 0.4\n",
    "\n",
    "labels = np.zeros((d1,d2,d3)).astype('uint16')\n",
    "\n",
    "final_idx = []\n",
    "good_cvec = []\n",
    "good_barcode = []\n",
    "good_mean_pixel = []\n",
    "lab = 31001\n",
    "\n",
    "for idx in tqdm(filtered_idx):\n",
    "    bm = barcode_match(barcodeC[idx, :], barcodeY, 5)\n",
    "    corr, sy, sty = barcode_correlation(C[idx,:], flat_full_stitch, sy, sty)\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    merged = np.logical_and(bm, corr > 0.75)\n",
    "    \n",
    "    if np.sum(merged[dy1*fovx:dy1*(fovx+1), dy2*fovy:dy2*(fovy+1), :]/ np.sum(merged)) > inpatch_thresh:\n",
    "        final_idx.append(idx)\n",
    "        labels[merged] = lab + idx\n",
    "    \n",
    "        vec = np.mean(get_A_pixels(Y, A[:,:,:,idx], 50), 0)\n",
    "\n",
    "        good_cvec.append(C[idx, :])\n",
    "        good_barcode.append(barcodeC[idx,:])\n",
    "        good_mean_pixel.append(vec)    \n",
    "    \n",
    "good_cvec = np.array(good_cvec)\n",
    "good_barcode = np.array(good_barcode)\n",
    "good_mean_pixel = np.array(good_mean_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T00:57:06.152452Z",
     "start_time": "2020-07-08T00:51:50.498685Z"
    }
   },
   "outputs": [],
   "source": [
    "io.imsave('/mp/nas2/axue/3_1_components_fullstitch.tif', fov_labels)\n",
    "np.savetxt('/mp/nas2/axue/3_1_barcode_fullstitch.csv', good_barcode, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/3_1_mp_fullstitch.csv', good_mean_pixel, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/3_1_cvec_fullstitch.csv', good_cvec, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T00:51:46.952364Z",
     "start_time": "2020-07-08T00:51:46.880633Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('/mp/nas2/axue/3_1_barcode_fullstitch.csv', good_barcode, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/3_1_mp_fullstitch.csv', good_mean_pixel, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/3_1_cvec_fullstitch.csv', good_cvec, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_label = 'full'\n",
    "\n",
    "pickle.dump(A, open(fov_label+\"_A.p\", \"wb\" ))\n",
    "pickle.dump(C, open(fov_label+\"_C.p\", \"wb\" ))\n",
    "pickle.dump(weights, open(fov_label+\"_weights.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pickle.load(open(fov_label+\"_A.p\", \"rb\" ))\n",
    "C = pickle.load(open(fov_label+\"_C.p\", \"rb\" ))\n",
    "weights = pickle.load(open(\"full_weights.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated Barcoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:02:19.520320Z",
     "start_time": "2020-07-01T19:02:18.511820Z"
    }
   },
   "outputs": [],
   "source": [
    "imagesc(np.sum(rawY, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:01:33.102346Z",
     "start_time": "2020-07-01T17:55:19.794909Z"
    }
   },
   "outputs": [],
   "source": [
    "barcodes = matrix_basecall(C, thresh_c = 1.25, thresh_d = 1.25)\n",
    "Y_basecall = np.reshape(matrix_basecall(flat_full_stitch,thresh_c = 1.25, thresh_d = 1.25), (d1,d2,d3, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes = matrix_basecall(C, thresh_c = 1.25, thresh_d = 1.25)\n",
    "Y_basecall = np.reshape(matrix_basecall(flatY,thresh_c = 1.25, thresh_d = 1.25), (d1,d2,d3, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T20:21:55.426853Z",
     "start_time": "2020-08-17T20:21:55.421546Z"
    }
   },
   "outputs": [],
   "source": [
    "ffv1, ffv2, ffv3 = 1870, 1946, 400\n",
    "fv1, fv2, fv3 = 468, 486, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T20:22:13.673273Z",
     "start_time": "2020-08-17T20:22:13.666109Z"
    }
   },
   "outputs": [],
   "source": [
    "ffv1/fv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T20:28:26.808746Z",
     "start_time": "2020-08-17T20:22:26.045425Z"
    }
   },
   "outputs": [],
   "source": [
    "upsample_labels = zoom(full_stitch_labels, (ffv1/fv1,ffv2/fv2, ffv3/fv3), order = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:29:19.240616Z",
     "start_time": "2020-08-18T04:29:19.231788Z"
    }
   },
   "outputs": [],
   "source": [
    "upsample_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T03:33:36.221421Z",
     "start_time": "2020-08-26T03:33:32.664299Z"
    }
   },
   "outputs": [],
   "source": [
    "full_stitch_labels = pickle.load(open(\"full_stitch_label.p\", \"rb\" ))\n",
    "unique_labels = np.unique(full_stitch_labels[full_stitch_labels > 0]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T03:35:06.457827Z",
     "start_time": "2020-08-26T03:35:06.452864Z"
    }
   },
   "outputs": [],
   "source": [
    "good_cvec = fullC[unique_labels, :]\n",
    "good_barcode = full_barcodeC[unique_labels, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T03:37:09.456967Z",
     "start_time": "2020-08-26T03:37:09.401858Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('/mp/nas2/axue/fullstitch_barcode.csv', good_barcode, delimiter=\",\")\n",
    "np.savetxt('/mp/nas2/axue/fullstitch_Cvec_original.csv', good_cvec, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cvec = []\n",
    "good_barcode = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T03:33:41.956662Z",
     "start_time": "2020-08-26T03:33:41.951779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35,  40,  44,  79,  91,  93,  99, 100, 101, 109, 118, 205, 206,\n",
       "       215, 255, 270, 277, 282, 283, 287, 293, 294, 296, 324, 325, 328,\n",
       "       335, 338, 341, 348, 375, 382, 388, 393, 401, 407, 411, 430, 435,\n",
       "       464, 475, 476, 509, 512, 513, 533, 548, 583, 586, 589, 594])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T22:30:22.810074Z",
     "start_time": "2020-08-03T22:30:22.799040Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = pickle.load(open('full_weights.p', 'rb'))\n",
    "rweights = np.reshape(weights, (4,3))\n",
    "\n",
    "Cvec = fullC[unique_labels, :]\n",
    "\n",
    "b1, bT = Cvec.shape\n",
    "barcodes = np.reshape(Cvec, (b1, 5, 3))\n",
    "barcodes = np.matmul(barcodes, rweights.T)\n",
    "barcodes = (barcodes / np.max(barcodes, -1, keepdims = True) == 1).astype('int')\n",
    "barcodes = np.reshape(barcodes, (b1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:49:37.340288Z",
     "start_time": "2020-08-03T17:47:59.800750Z"
    }
   },
   "outputs": [],
   "source": [
    "barcode_full_stitch = basecall_with_weights(full_stitch, rweights)\n",
    "sy, sty = calc_sy(flat_full_stitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T22:48:34.555057Z",
     "start_time": "2020-08-03T22:47:17.286255Z"
    }
   },
   "outputs": [],
   "source": [
    "d1,d2,d3,T = full_stitch.shape\n",
    "corr = barcode_correlation(Cvec[idx,:], flat_full_stitch, sy, sty)[0]\n",
    "corr += 1\n",
    "corr *= 255/2\n",
    "corr = corr.astype('uint8')\n",
    "corr = np.reshape(corr, (d1,d2,d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T22:56:18.547666Z",
     "start_time": "2020-08-03T22:56:04.096809Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y,z = center_of_mass_norm(full_stitch_labels == u_idx, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T23:01:49.968959Z",
     "start_time": "2020-08-03T23:01:49.961299Z"
    }
   },
   "outputs": [],
   "source": [
    "str(np.array([x,y,z]).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T23:01:02.533062Z",
     "start_time": "2020-08-03T23:01:02.524541Z"
    }
   },
   "outputs": [],
   "source": [
    "str(np.argmax(np.reshape(barcodes[idx, :], (-1, 5, 4)), -1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T18:45:49.944258Z",
     "start_time": "2020-08-04T18:27:34.832696Z"
    }
   },
   "outputs": [],
   "source": [
    "blur_fp = []\n",
    "for idx in tqdm(range(len(unique_labels))):\n",
    "    u_idx = unique_labels[idx]\n",
    "    \n",
    "    lfp = '/mp/nas2/axue/blur/blurmap_comp' + str(u_idx)+'.tif'\n",
    "    bl = (full_stitch_labels == u_idx)\n",
    "    bl = gaussian_filter(bl, [1,1,1], mode = 'constant', output = 'double')\n",
    "    bl *= 65536 / 100\n",
    "    bl = bl.astype('uint16')\n",
    "    \n",
    "    bl = np.moveaxis(bl, -1, 0)\n",
    "    io.imsave(lfp, bl, check_contrast = False)\n",
    "    \n",
    "    blur_fp.append(lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T00:24:14.421977Z",
     "start_time": "2020-08-05T00:24:14.414346Z"
    }
   },
   "outputs": [],
   "source": [
    "vast_loc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T00:24:26.553334Z",
     "start_time": "2020-08-05T00:24:26.544200Z"
    }
   },
   "outputs": [],
   "source": [
    "loc2 = []\n",
    "vast_loc2 = []\n",
    "\n",
    "for i in range(len(loc)):\n",
    "    x,y,z = loc[i].strip('[]').split()\n",
    "    loc2.append('(' + y + ', ' + x + ', ' + z + ')')\n",
    "    \n",
    "    vx,vy,vz = vast_loc[i].strip('[]').split()\n",
    "    vast_loc2.append(\"(\" + vy + ', ' + vx + ', ' + vz + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T02:36:52.835354Z",
     "start_time": "2020-08-04T00:53:05.048877Z"
    }
   },
   "outputs": [],
   "source": [
    "loc = []\n",
    "vast_loc = []\n",
    "num_barcodes = []\n",
    "corr_fp = []\n",
    "barcode_fp = []\n",
    "seg_fp = []\n",
    "for idx in tqdm(range(len(unique_labels))):\n",
    "    u_idx = unique_labels[idx]\n",
    "    bm = np.squeeze(np.dot(barcode_full_stitch, barcodes[idx, :].T)).astype('uint8')\n",
    "    \n",
    "    corr = barcode_correlation(Cvec[idx,:], flat_full_stitch, sy, sty)[0]\n",
    "    corr += 1\n",
    "    corr *= 255/2\n",
    "    corr = corr.astype('uint8')\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    \n",
    "    seg = (full_stitch_labels == u_idx).astype('uint8') * 255\n",
    "    \n",
    "    x,y,z = center_of_mass_norm(full_stitch_labels == u_idx, order = 0.5)\n",
    "    \n",
    "    loc.append(str(np.array([x,y,z]).astype('int')))\n",
    "    vast_loc.append(str(np.array([4*x,4*y,4*z]).astype('int')))\n",
    "    \n",
    "    num_barcodes.append(str(np.argmax(np.reshape(barcodes[idx, :], (-1, 5, 4)), -1)+1))\n",
    "    \n",
    "    bfp = '/mp/nas2/axue/distancemap/hammingdist_map_comp' + str(u_idx)+'.tif'\n",
    "    cfp = '/mp/nas2/axue/distancemap/correlation_map_comp' + str(u_idx)+'.tif'\n",
    "    sfp = '/mp/nas2/axue/segments/segmentation_comp' + str(u_idx)+'.tif'\n",
    "    \n",
    "    corr_fp.append(cfp)\n",
    "    barcode_fp.append(bfp)\n",
    "    seg_fp.append(sfp)\n",
    "        \n",
    "    seg = np.moveaxis(seg, -1, 0)\n",
    "    bm = np.moveaxis(bm, -1, 0)\n",
    "    corr = np.moveaxis(corr, -1, 0)\n",
    "    \n",
    "    io.imsave(bfp, bm)\n",
    "    io.imsave(cfp, corr)\n",
    "    io.imsave(sfp, seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T00:24:30.513236Z",
     "start_time": "2020-08-05T00:24:30.502763Z"
    }
   },
   "outputs": [],
   "source": [
    "tracker = pd.DataFrame(\n",
    "    {'Imported Segment Number': list(range(1, len(unique_labels)+1)),\n",
    "     'Auto-Segment Number': list(unique_labels),\n",
    "     'Barcode': num_barcodes,\n",
    "     'VAST Segment Center': vast_loc2,\n",
    "     '4x Downsample Center': loc2,\n",
    "     'Correlation Map Filepath': corr_fp, \n",
    "     'Hamming Distance Filepath': barcode_fp,\n",
    "     'Downsampled Label Mask Filepath': seg_fp,\n",
    "     'Blurred Mask Filepath': blur_fp\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T00:24:32.946480Z",
     "start_time": "2020-08-05T00:24:32.935188Z"
    }
   },
   "outputs": [],
   "source": [
    "tracker.to_csv('Segmentation_Tracking.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:03:34.788209Z",
     "start_time": "2020-07-21T05:03:30.267456Z"
    }
   },
   "outputs": [],
   "source": [
    "imagesc(np.sum(full_stitch, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T04:50:45.864305Z",
     "start_time": "2020-06-22T04:49:28.172036Z"
    }
   },
   "outputs": [],
   "source": [
    "percentiles = list(range(80, 100))\n",
    "vals = []\n",
    "for pct in tqdm(percentiles):\n",
    "    temp = []\n",
    "\n",
    "    for idx in range(Yhp.shape[-1]):\n",
    "        temp.append(np.percentile(Yhp[:,:,:,idx], pct))\n",
    "    vals.append(temp)\n",
    "    \n",
    "vals = np.array(vals)\n",
    "nvals = vals / np.max(vals, 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T04:52:18.231416Z",
     "start_time": "2020-06-22T04:52:18.026721Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T04:53:46.732914Z",
     "start_time": "2020-06-22T04:53:46.512513Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"chan\" + str(i) for i in range(15)]\n",
    "for idx in range(2, 15, 3):\n",
    "    plt.plot(nvals[:, idx], label=labels[idx])\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T04:48:19.940430Z",
     "start_time": "2020-06-22T04:48:19.259028Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "thresh = 99\n",
    "timg = Yhp[:,:,:,idx] > np.percentile(Yhp[:,:,:,idx], thresh)\n",
    "imagesc(np.sum(timg, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:53:57.974354Z",
     "start_time": "2020-06-18T17:53:55.544912Z"
    }
   },
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "Yslice = Yhp[:,:,:,s_idx]\n",
    "Yslice = Yslice[Yslice > np.percentile(Yslice, 99)]\n",
    "counts, bins = np.histogram(Yslice, 1000)\n",
    "plt.hist(bins[:-1], weights = counts, bins = bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:13:04.367745Z",
     "start_time": "2020-06-18T17:13:03.990628Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 65\n",
    "normed = norm_by_round(C[idx, :])\n",
    "normed = np.reshape(normed, (5, 3))\n",
    "plt.plot(normed[:, 0], 'r-')\n",
    "plt.plot(normed[:, 1], 'g-')\n",
    "plt.plot(normed[:, 2], 'b-')\n",
    "\n",
    "bc = barcodes[idx, :]\n",
    "bc = np.reshape(bc, (5, -1))\n",
    "imagesc(bc, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:19:13.082170Z",
     "start_time": "2020-06-18T17:19:07.725830Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in filtered_idx:\n",
    "    plt.figure(1,1)\n",
    "    bm = barcode_match(barcodes[idx, :], Y_basecall, 5)\n",
    "    corr = barcode_correlation(C[idx,:], flatY, sy, sty)[0]\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    merged = np.logical_and(bm, corr > 0.75)\n",
    "    imagesc(np.sum(merged,2))\n",
    "    x,y,z = center_of_mass(merged)\n",
    "    plt.plot(y,x, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T07:42:35.279362Z",
     "start_time": "2020-06-25T07:42:34.423761Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y,z = center_of_mass(merged)\n",
    "\n",
    "xpos, ypos, zpos = np.where(merged > 0)\n",
    "\n",
    "distances = []\n",
    "for idx in tqdm(range(xpos.shape[-1])):\n",
    "    dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "    distances.append(dist ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:11.589213Z",
     "start_time": "2020-07-01T00:53:11.356583Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(distances, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dist = []\n",
    "for fidx in filtered_idx:\n",
    "    all_dist = all_dist + distances[fidx]\n",
    "    \n",
    "counts, bins = np.histogram(all_dist, 30)\n",
    "\n",
    "#put data into heatmap format\n",
    "heatmap_data = []\n",
    "for fidx in filtered_idx:\n",
    "    heatmap_data.append(np.histogram(distances[fidx], bins)[0])\n",
    "    \n",
    "heatmap_data = np.array(heatmap_data).T[1:15, :]\n",
    "\n",
    "clustergrid = seaborn.clustermap(heatmap_data, row_cluster = False, xticklabels = filtered_idx)\n",
    "#clustergrid = clustergrid.fig.suptitle('Distance to Center of Mass of Segmentation') \n",
    "\n",
    "og_barcodes = barcodes[filtered_idx]\n",
    "reord_barcodes = og_barcodes[clustergrid.dendrogram_col.reordered_ind]\n",
    "\n",
    "for idx in tqdm(filtered_idx[clustergrid.dendrogram_col.reordered_ind]):\n",
    "    bm = barcode_match(barcodes[idx, :], Y_basecall, 5)\n",
    "    corr, sy, sty = barcode_correlation(C[idx,:], flatY, sy, sty)\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    merged = np.logical_and(bm, corr > 0.75)\n",
    "    print(np.sum(dilation(merged, ball(1))) / np.sum(merged))\n",
    "    imagesc(np.sum(merged,2))\n",
    "    x,y,z = center_of_mass(merged)\n",
    "    plt.plot(y,x, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T17:11:11.430369Z",
     "start_time": "2020-07-22T17:11:11.424086Z"
    }
   },
   "outputs": [],
   "source": [
    "#fast distance calculation\n",
    "for idx in final_idx:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T17:38:05.351064Z",
     "start_time": "2020-07-22T17:24:31.395969Z"
    }
   },
   "outputs": [],
   "source": [
    "coms = []\n",
    "ps = []\n",
    "\n",
    "for idx in tqdm(final_idx):\n",
    "    x,y,z = center_of_mass_norm(full_stitch_labels == idx, 0.5)\n",
    "    xpos, ypos, zpos = np.where(full_stitch_labels == idx)\n",
    "    \n",
    "    coms.append((x,y,z))\n",
    "    ps.append((xpos, ypos, zpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T17:39:22.231908Z",
     "start_time": "2020-07-22T17:39:22.192834Z"
    }
   },
   "outputs": [],
   "source": [
    "x_distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T17:49:42.057562Z",
     "start_time": "2020-07-22T17:49:33.589270Z"
    }
   },
   "outputs": [],
   "source": [
    "x_distances = []\n",
    "y_distances = []\n",
    "\n",
    "for i in tqdm(range(len(final_idx))):\n",
    "    x,y,z = coms[i]\n",
    "    xpos, ypos, zpos = ps[i]\n",
    "    \n",
    "    x_dist = []\n",
    "    y_dist = []\n",
    "    for j in range(len(xpos)):\n",
    "        x_dist.append(((xpos[j] - x)**2 + (zpos[j] - z)**2)**0.5)\n",
    "        y_dist.append(((ypos[j] - y)**2 + (zpos[j] - z)**2)**0.5)\n",
    "    x_distances.append(x_dist)\n",
    "    y_distances.append(y_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T18:01:44.596179Z",
     "start_time": "2020-07-22T18:01:41.776120Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_dist = []\n",
    "for fidx in range(len(final_idx)):\n",
    "    all_dist = all_dist + x_distances[fidx] + y_distances[fidx]\n",
    "    \n",
    "counts, bins = np.histogram(all_dist, 30)\n",
    "\n",
    "#put data into heatmap format\n",
    "heatmap_data_x = []\n",
    "heatmap_data_y = []\n",
    "for fidx in range(len(final_idx)):\n",
    "    heatmap_data_x.append(np.histogram(x_distances[fidx], bins)[0])\n",
    "    heatmap_data_y.append(np.histogram(y_distances[fidx], bins)[0])\n",
    "\n",
    "heatmap_data_x = np.array(heatmap_data_x).T\n",
    "heatmap_data_y = np.array(heatmap_data_y).T\n",
    "heatmap_data_x[heatmap_data_x <= 0] = 1\n",
    "heatmap_data_y[heatmap_data_y <= 0] = 1\n",
    "\n",
    "heatmap_data_x = np.log2(heatmap_data_x)\n",
    "heatmap_data_y = np.log2(heatmap_data_y)\n",
    "\n",
    "clustergrid = seaborn.clustermap(heatmap_data_x, row_cluster = False, col_cluster = False, xticklabels = final_idx, yticklabels = np.round(bins[1:], 1))\n",
    "ax = clustergrid.ax_heatmap\n",
    "clustergrid = clustergrid.fig.suptitle('Vertical Distance of Cell Tracing from Center of Mass') \n",
    "ax.set_xlabel(\"Cell Index\")\n",
    "ax.set_ylabel(\"Upper Bound of Histogram Bin\")\n",
    "\n",
    "clustergrid = seaborn.clustermap(heatmap_data_y, row_cluster = False, col_cluster = False, xticklabels = final_idx, yticklabels = np.round(bins[1:], 1))\n",
    "ax = clustergrid.ax_heatmap\n",
    "clustergrid = clustergrid.fig.suptitle('Horizontal Distance of Cell Tracing from Center of Mass') \n",
    "ax.set_xlabel(\"Cell Index\")\n",
    "ax.set_ylabel(\"Upper Bound of Histogram Bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesc(full_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T18:13:44.981963Z",
     "start_time": "2020-07-22T18:13:44.811553Z"
    }
   },
   "outputs": [],
   "source": [
    "imagesc(np.max())\n",
    "\n",
    "plt.text(0.1, 0.1, \"hello\", color = (1, 0, 0), ha=\"right\", va=\"top\",\n",
    "         bbox=dict(boxstyle=\"square\",\n",
    "                   ec=(0.1, 0.1, 0.1),\n",
    "                   fc=(0.95, 0.95, 0.95),\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T03:53:29.781309Z",
     "start_time": "2020-07-09T03:53:14.189490Z"
    }
   },
   "outputs": [],
   "source": [
    "imagesc(np.sum(full_stitch, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T18:15:51.450067Z",
     "start_time": "2020-07-22T18:15:51.443360Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "cmap = colors.ListedColormap(['r', 'g', 'b', 'y'])\n",
    "bounds=[0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T18:15:53.144828Z",
     "start_time": "2020-07-22T18:15:53.139124Z"
    }
   },
   "outputs": [],
   "source": [
    "barcodes = np.argmax(np.reshape(full_barcodeC[final_idx], (-1, 5, 4)), -1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T18:32:48.789006Z",
     "start_time": "2020-07-22T18:32:43.380743Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,70))\n",
    "labels2 = np.max(full_stitch_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "plt.imshow(col_labels)\n",
    "colors = color.label2rgb(final_idx, bg_label = 0)\n",
    "for idx in range(len(final_idx)):\n",
    "    fidx = final_idx[idx]\n",
    "    plt.text(coms[idx][1], coms[idx][0], str(fidx), color = colors[idx], ha=\"right\", va=\"top\",\n",
    "             bbox=dict(boxstyle=\"square\",\n",
    "                       ec=(0.1, 0.1, 0.1),\n",
    "                       fc=(0.95, 0.95, 0.95),\n",
    "                       ))\n",
    "plt.savefig('test_labels.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:07:26.277077Z",
     "start_time": "2020-08-05T17:07:26.239582Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(num_barcodes.T, norm = norm, cmap = cmap)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Full Stitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:09:33.547107Z",
     "start_time": "2020-08-06T17:09:16.957446Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = '/mp/nas2/DG/iarpa_virtual_tiles/1_0/4_registration/''richieseq_round001_ch00_affine.tif'\n",
    "test = io.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:13:01.878811Z",
     "start_time": "2020-08-06T17:11:50.145642Z"
    }
   },
   "outputs": [],
   "source": [
    "rs = zoom(ds, (4, 4, 4), order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:11:18.588098Z",
     "start_time": "2020-08-06T17:11:15.269237Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = zoom(test, (0.25, 0.25, 0.25), order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:25:40.592187Z",
     "start_time": "2020-08-06T17:25:14.178336Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = test[:, :1944, :].astype('float64') - rs[:1870,:, :].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:28:40.882148Z",
     "start_time": "2020-08-06T17:28:40.542880Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(diff[:,:,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:26:43.235753Z",
     "start_time": "2020-08-06T17:26:40.323383Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.max(diff, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:21:56.670296Z",
     "start_time": "2020-08-06T17:21:56.664020Z"
    }
   },
   "outputs": [],
   "source": [
    "rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:21:53.232147Z",
     "start_time": "2020-08-06T17:21:53.225912Z"
    }
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T17:10:00.226375Z",
     "start_time": "2020-08-06T17:10:00.220952Z"
    }
   },
   "outputs": [],
   "source": [
    "test = np.moveaxis(test, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T16:59:23.435566Z",
     "start_time": "2020-08-05T16:57:54.460544Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dim = 250\n",
    "r = img_dim // 2\n",
    "\n",
    "imgs = []\n",
    "for ridx in tqdm(range(len(unique_labels))):\n",
    "    idx = unique_labels[ridx]\n",
    "\n",
    "    idx_colors = color.label2rgb(unique_labels)\n",
    "    \n",
    "    labels2 = np.max(full_stitch_labels, 2)\n",
    "    col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "    match = np.max(full_stitch_labels == idx, 2)\n",
    "    sub_labels = col_labels\n",
    "    sub_labels[~match, :] = 0\n",
    "    sub_labels[match, :] = idx_colors[np.where(unique_labels == idx)[0][0]]\n",
    "    \n",
    "    x,y,z = loc_raw[ridx]\n",
    "    \n",
    "    x = max(r, min(x, d1-1-r))\n",
    "    y = max(r, min(y, d2-1-r))\n",
    "    \n",
    "    imgs.append(sub_labels[x-r:x+r, y-r:y+r, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T16:59:23.546412Z",
     "start_time": "2020-08-05T16:59:23.437730Z"
    }
   },
   "outputs": [],
   "source": [
    "cell_imgs = np.concatenate(imgs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:05:05.559510Z",
     "start_time": "2020-08-05T19:05:04.256141Z"
    }
   },
   "outputs": [],
   "source": [
    "viewmask(full_stitch_labels == 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:32:19.575768Z",
     "start_time": "2020-08-05T17:32:07.994326Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 510))\n",
    "plt.imshow(cell_imgs)\n",
    "plt.savefig('draft_cellbodies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T16:23:21.274463Z",
     "start_time": "2020-08-05T16:23:21.267535Z"
    }
   },
   "outputs": [],
   "source": [
    "loc_raw = []\n",
    "\n",
    "for i in range(len(loc)):\n",
    "    x,y,z = loc[i].strip('[]').split()\n",
    "    loc_raw.append([int(x),int(y),int(z)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:31:56.102121Z",
     "start_time": "2020-08-05T17:31:52.065340Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "cmap = colors.ListedColormap(['r', 'g', 'b', 'y'])\n",
    "bounds=[0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "plt.figure(figsize = (10,510))\n",
    "plt.imshow(num_barcodes, norm = norm, cmap = cmap)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('draft_barcodes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T16:10:18.710127Z",
     "start_time": "2020-08-05T16:10:18.702006Z"
    }
   },
   "outputs": [],
   "source": [
    "num_barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T16:10:13.267825Z",
     "start_time": "2020-08-05T16:10:13.262156Z"
    }
   },
   "outputs": [],
   "source": [
    "num_barcodes = np.argmax(np.reshape(barcodes, (-1, 5, 4)), -1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T02:46:09.553048Z",
     "start_time": "2020-07-10T02:46:09.127698Z"
    }
   },
   "outputs": [],
   "source": [
    "view_components(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Per Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T03:31:48.440295Z",
     "start_time": "2020-07-10T03:31:38.564389Z"
    }
   },
   "outputs": [],
   "source": [
    "full_stitch_small = zoom(full_stitch, (0.25, 0.25, 0.25, 1), order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T03:32:03.512712Z",
     "start_time": "2020-07-10T03:32:03.023056Z"
    }
   },
   "outputs": [],
   "source": [
    "imagesc(np.sum(full_stitch_small, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:32:52.854156Z",
     "start_time": "2020-07-08T05:32:52.849545Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T16:09:23.474658Z",
     "start_time": "2020-07-15T16:09:22.352818Z"
    }
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(full_stitch_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T05:48:44.120052Z",
     "start_time": "2020-07-08T05:48:16.831182Z"
    }
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(fov_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T15:44:50.271610Z",
     "start_time": "2020-07-08T15:33:50.778510Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(fov_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T16:12:58.837651Z",
     "start_time": "2020-07-15T16:12:55.527515Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels2 = np.max(fov_labels, 2)\n",
    "col_labels = color.label2rgb(labels2, bg_label = 0)\n",
    "plt.figure(figsize=(25,70))\n",
    "plt.imshow(col_labels)\n",
    "plt.savefig('full_stitch_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_inputs = [[input_] for input_ in inputs]\n",
    "full_weights = []\n",
    "\n",
    "for inputs in tqdm(full_inputs):\n",
    "    weights = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]]).astype('d')\n",
    "    matrix_gradient = grad(basecalling_loss)\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    training_steps = [500, 500, 500]\n",
    "    print(\"Initial loss:\", basecalling_loss(weights))\n",
    "    for train_idx in range(len(learning_rates)):\n",
    "        for i in range(training_steps[train_idx]):\n",
    "            #if i % 10 == 0:\n",
    "                #print(\"Current loss:\", basecalling_loss(weights))\n",
    "            weights -= matrix_gradient(weights) * learning_rates[train_idx]\n",
    "\n",
    "    print(\"Trained loss:\", basecalling_loss(weights))\n",
    "    full_weights.append(weights)\n",
    "    \n",
    "vals = []\n",
    "size = []\n",
    "dilation_factor = []\n",
    "distances = []\n",
    "for idx in tqdm(range(A.shape[-1])):\n",
    "    \n",
    "    weights = full_weights[idx]\n",
    "    rweights = np.reshape(weights, (4,3))\n",
    "\n",
    "    d1, d2, d3, T = Y.shape\n",
    "    barcodeYs = np.reshape(Y, (d1, d2, d3, 5, 3))\n",
    "    barcodeYs = np.matmul(barcodeYs, rweights.T)\n",
    "    barcodeYs = (barcodeYs / np.max(barcodeYs, -1, keepdims = True) == 1).astype('int')\n",
    "    barcodeYs = np.reshape(barcodeYs, (d1,d2,d3, -1))\n",
    "\n",
    "    b1, bT = C.shape\n",
    "    barcodeC = np.reshape(C, (b1, 5, 3))\n",
    "    barcodeC = np.matmul(barcodeC, rweights.T)\n",
    "    barcodeC = (barcodeC / np.max(barcodeC, -1, keepdims = True) == 1).astype('int')\n",
    "    barcodeC = np.reshape(barcodeC, (b1,-1))\n",
    "    \n",
    "    bm = barcode_match(barcodeC[idx, :], barcodeYs, 5)\n",
    "    corr, sy, sty = barcode_correlation(C[idx,:], flatY, sy, sty)\n",
    "    corr = np.reshape(corr, (d1,d2,d3))\n",
    "    merged = np.logical_and(bm, corr > 0.75)\n",
    "    sens = (np.sum(A[merged,idx]) / np.sum(A[:,:,:,idx]))\n",
    "    spec = (np.sum(merged)/merged.size)\n",
    "    vals.append(sens/spec)\n",
    "    size.append(np.sum(merged))\n",
    "    dilation_factor.append(np.sum(dilation(merged, ball(1))) / np.sum(merged))\n",
    "    \n",
    "    x,y,z = center_of_mass_norm(merged, 0.5)\n",
    "    xpos, ypos, zpos = np.where(merged > 0)\n",
    "\n",
    "    distance = []\n",
    "    for idx in range(xpos.shape[-1]):\n",
    "        dist= (xpos[idx]-x)**2 + (ypos[idx]-y)**2 + (zpos[idx]-z)**2\n",
    "        distance.append(dist ** 0.5)\n",
    "    distances.append(distance)\n",
    "\n",
    "vals = np.array(vals)\n",
    "size = np.array(size)\n",
    "dilation_factor = np.array(dilation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T22:02:38.866888Z",
     "start_time": "2020-06-22T22:02:38.830881Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_spatial_correlation(A, blur = False, sigma = [0.5,0.5,0.5]):\n",
    "    n_cells = A.shape[-1]\n",
    "    if blur:\n",
    "        A = A.copy()\n",
    "        for i in tqdm(range(n_cells)):\n",
    "            A[:,:,:,i] = gaussian_filter(A[:,:,:,i], sigma, mode = 'constant', output = 'double')\n",
    "    \n",
    "    A = np.reshape(A, (-1, n_cells))\n",
    "\n",
    "    cellsum = np.sum(A, 0, keepdims = True)\n",
    "    A = A / cellsum \n",
    "    \n",
    "    spatial_overlap = np.zeros((n_cells, n_cells))\n",
    "    \n",
    "    for i in tqdm(range(n_cells-1)):\n",
    "        i_pos = A[:, i] > 0\n",
    "        tempA = A[i_pos, :]\n",
    "        subtract_vec = tempA[:, [i]]\n",
    "        tempA = tempA[:, i+1:]\n",
    "        tempA = tempA - subtract_vec\n",
    "        tempA[tempA > 0] = 0\n",
    "        overlap = np.sum(tempA, 0) + 1\n",
    "        spatial_overlap[i, i+1:] = overlap\n",
    "        spatial_overlap[i+1:, i] = overlap\n",
    "            \n",
    "    return spatial_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T22:02:46.603297Z",
     "start_time": "2020-06-22T22:02:41.141863Z"
    }
   },
   "outputs": [],
   "source": [
    "scf = fast_spatial_correlation(tA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T22:05:24.135793Z",
     "start_time": "2020-06-22T22:03:58.329541Z"
    }
   },
   "outputs": [],
   "source": [
    "tA = A[:,:,:, 0:20]\n",
    "sc = create_spatial_correlation(tA)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
